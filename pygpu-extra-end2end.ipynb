{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c738ad5-6f83-4aec-abdd-da99619de9b6",
   "metadata": {},
   "source": [
    "# **Evaluating Your Options for Numerical Computing in Pure Python with Numba**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0095abd3-c33b-46db-9b2c-c6f590a96c66",
   "metadata": {},
   "source": [
    "## **Prerequisites**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b1063f-99fb-4a45-bee9-3a5973c1d7f8",
   "metadata": {},
   "source": [
    "This tutorial assume proficiency in Python and the following libraries:\n",
    "\n",
    "* NumPy\n",
    "* Scikit-Learn\n",
    "* Numba\n",
    "\n",
    "Demo System - Benchmarking was performed on a T4 16 GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cf4fdc-22ce-4a80-b72b-df7a456ffcaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8124242d-dc14-4d80-a087-1296aa9f7baa",
   "metadata": {},
   "source": [
    "## **Problem Overview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b18383-2477-4c7e-8354-7a4c7e9fd3d5",
   "metadata": {},
   "source": [
    "In this notebook, we  survey techniques for numerical computing in pure Python. We leverage a proxy geospatial nearest neighbor problem to guide us through an evaluation of several libraries and methodologies. In this use case, we aim to resolve geospatial observations to their nearest reference points with an added complexity. Our complication adds dynamics to the problem allowing each reference point to move and the set of observations to change on a reoccurring basis. These complexities imply a need to recompute each nearest neighbor at each timestep -- emphasizing the need for high performance techiques. \n",
    "\n",
    "Because of its simplicity and arithmetic intensity, we focus our attention on the brute force nearest neighbor technique using the haversine great circle distance formula as our distance metric. This is a popular formula used to calculate the distance between two points on earth.\n",
    "\n",
    "<center><a href=\"https://en.wikipedia.org/wiki/Haversine_formula\"><img src=\"./media/haversine-graphic.png\" alt=\"Haversine\" style=\"width: 150;\"></a></center></br>\n",
    "\n",
    "The graphic below illustrates the dynamic nature of our problem. From left to write, we can observe the dynamics of the system at each timestep -- with colored regions representing nearest neighbor decision boundaries for each reference point and points representing observations.\n",
    "\n",
    "<center><img src=\"./media/visualization.PNG\" alt=\"Visualization\" style=\"width: 1000;\"/></center>\n",
    "\n",
    "In this notebook, we will evalutate the following single threaded CPU techniques:\n",
    "\n",
    "* Numba CPU Kernel\n",
    "\n",
    "In addition, we will evalutate several single GPU techniques:\n",
    "\n",
    "* Hand tuned Numba CUDA Kernel\n",
    "\n",
    "In the end, we'll compare their performance on a moderate sized problem (defined below) and expand our numerical computing toolbox with a few new tricks.\n",
    "\n",
    "**Spoiler Alert -- The GPU techniques each out perform the CPU techniques by at least several orders of magnitude.**\n",
    "\n",
    "Because many of the CPU functions take so long, we use the ```%%time``` magic function and comment out ```%%timeit``` to generate benchmarks.\n",
    "\n",
    "Since many of the CPU techniques will take a very long time to complete, we provide an overview of the expected performance measured on a T4.\n",
    "\n",
    "<center><img src=\"./media/small-problem-single.PNG\" alt=\"PerfTable\" style=\"width: 1250;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873b016d-8a89-4203-a4db-12e25874dc73",
   "metadata": {},
   "source": [
    "# **Numba CPU/GPU Experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745645dc-c50f-4e0b-b134-51775098d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "\n",
    "from numba import (cuda, \n",
    "                   uint32, \n",
    "                   int32, \n",
    "                   float32,\n",
    "                   types, \n",
    "                   jit, \n",
    "                   prange)\n",
    "\n",
    "from cupyx.time import repeat\n",
    "from cuml.neighbors import NearestNeighbors as cuNearestNeighbors\n",
    "import rmm\n",
    "from src.simulator import generate_geos\n",
    "\n",
    "from src.utils import (query_available_memory, \n",
    "                       check_accuracy,\n",
    "                       check_accuracy_h2h)\n",
    "\n",
    "from math import sin, cos, sqrt, asin\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf3d97c-9db4-45f2-8187-ea0da6e91770",
   "metadata": {},
   "source": [
    "Define constants for the size of our experiment and evaluation criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e4e498-cbf0-4b18-b71c-166c10ee0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_OBS, N_REF = 2**16, 2**13\n",
    "N_OBS_VAL, N_REF_VAL = 500, 200 # check accuracy\n",
    "print(\"Problem Size (N_OBS * N_REF): {:.2f}B\".format(N_OBS * N_REF * 1e-9))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba76bfa1-08ee-4709-a1cc-fdb79433e5f8",
   "metadata": {},
   "source": [
    "## **RAPIDS Memory Manager**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ba5e12-8688-4d3d-a369-ae2a76c96b32",
   "metadata": {},
   "source": [
    "The RAPIDS Memory Manager (RMM) provides us finer grained control over memory allocations. Each memory allocation strategy comes with performance and data movement considerations.\n",
    "\n",
    "Since our experiments will use a fair bit of GPU memory and we desire the fastest performance, let's reinitialize the RMM by pre-allocating our initial pool size on the device. With our available GPUs we will be allocating 14GB.\n",
    "\n",
    "Note: be sure to free up memory from other notebooks/applications to maximize resources for these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368d7b12-ae21-4fc1-adc0-24286cf76626",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = cp.cuda.device.get_device_id()\n",
    "rmm.rmm.reinitialize(pool_allocator=True, initial_pool_size=14000000000, devices=device)\n",
    "cp.cuda.Device(device).use()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d9797b-74c4-49e9-aae2-1ecccab59fef",
   "metadata": {},
   "source": [
    "## **Generate Synthetic Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23c0c27-368a-438e-abfa-b9d08634c4fd",
   "metadata": {},
   "source": [
    "Generate a moderate sized synthetic dataset and smaller validation dataset to run our experiments using an included utility function. These datasets represent the following:\n",
    "\n",
    "* ```d_obs``` contains ```N_OBS``` geospatial observations in radians on the GPU, used for our moderate scale benchmark\n",
    "* ```d_ref``` contains ```N_REF``` geospatial reference points in radians on the GPU, used for our moderate scale benchmark\n",
    "* ```d_obs_val``` contains ```N_OBS_VAL``` geospatial observations in radians on the GPU, used to validate accuracy\n",
    "* ```d_ref_val``` contains ```N_REF_VAL``` geospatial reference points in radians on the GPU, used to validate accuracy\n",
    "* ```h_``` prefixes represent copies of these data on the host to use with the CPU techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35760e1-4856-4e4d-abf6-d93331c33ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_ref = generate_geos(N_REF, random_state=1)\n",
    "d_obs = generate_geos(N_OBS, random_state=2)\n",
    "\n",
    "h_ref = d_ref.get()\n",
    "h_obs = d_obs.get()\n",
    "\n",
    "d_ref_val = generate_geos(N_REF_VAL, random_state=1)\n",
    "d_obs_val = generate_geos(N_OBS_VAL, random_state=2)\n",
    "\n",
    "h_ref_val = d_ref_val.get()\n",
    "h_obs_val = d_obs_val.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af7fb19-4c68-4448-9947-219011ace580",
   "metadata": {},
   "source": [
    "## **Numba CPU Kernel**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aacbf8-92a0-4a44-80a6-576eb346e08d",
   "metadata": {},
   "source": [
    "[Numba](https://numba.pydata.org/) translates Python functions to optimized machine code at runtime using the industry-standard LLVM compiler library. Numba-compiled numerical algorithms in Python can approach the speeds of C or FORTRAN.\n",
    "\n",
    "Here, we leverage a Numba JIT compiled kernel based on our double for loop implementation and observe non-trivial speedups when compared to our baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3633f7e9-129b-44a6-bf39-65aefe1a87ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True, fastmath=True)\n",
    "def numba_cpu_haversine(lat1, lon1, lat2, lon2):\n",
    "\n",
    "    return 2.0 * asin(\n",
    "        sqrt(sin((lat2 - lat1) / 2.0)**2 + \\\n",
    "             cos(lat1) * \\\n",
    "             cos(lat2) * \\\n",
    "             sin((lon2 - lon1) / 2.0)**2)\n",
    "    )      \n",
    "\n",
    "@jit(nopython=True)\n",
    "def numba_cpu_solve(a, b):\n",
    "    \n",
    "    out_idx = np.empty(\n",
    "        (a.shape[0]), dtype=np.uint32)\n",
    "    \n",
    "    out_dist = np.empty(\n",
    "        (a.shape[0]), dtype=np.float32)\n",
    "    \n",
    "    for obs_idx in range(a.shape[0]):\n",
    "        \n",
    "        glob_min_dist = 1e11\n",
    "        glob_min_idx = 0\n",
    "        \n",
    "        for ref_idx in range(b.shape[0]):\n",
    "            \n",
    "            temp_dist = numba_cpu_haversine(\n",
    "                a[obs_idx,0],\n",
    "                a[obs_idx, 1],\n",
    "                b[ref_idx, 0],\n",
    "                b[ref_idx, 1])\n",
    "            \n",
    "            if temp_dist < glob_min_dist:\n",
    "                glob_min_dist = temp_dist\n",
    "                glob_min_idx = ref_idx\n",
    "        \n",
    "        out_dist[obs_idx] = glob_min_dist\n",
    "        out_idx[obs_idx] = glob_min_idx\n",
    "        \n",
    "    return out_idx, out_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cea99f-3e34-4ac8-a214-45c70bc05c56",
   "metadata": {},
   "source": [
    "Verify our Numba CPU kernel is producing the correct results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415e250d-eede-4adb-bf0c-d14379f927c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_idx_nb_cpu_val, out_dist_nb_cpu_val = \\\n",
    "    numba_cpu_solve(h_obs_val, h_ref_val)\n",
    "\n",
    "print(\"Accuracy - Numba Single Threaded CPU:\", \n",
    "      check_accuracy(\n",
    "          d_obs_val, d_ref_val,\n",
    "          out_idx_nb_cpu_val, out_dist_nb_cpu_val)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7518a5-c4e4-4ff6-8f70-60bd8b8ff19b",
   "metadata": {},
   "source": [
    "This Numba CPU routine completes on the demo system in ~35.4s -- 9,220 x faster than our baseline, but a little slower than our NumPy example. Good news is its more memory efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f32a88-5c46-429e-bf05-f456a20597ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#%%timeit\n",
    "out_idx_nb_cpu, out_dist_nb_cpu = numba_cpu_solve(h_obs, h_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4c30e-0eb0-43ae-928d-5395d78c804c",
   "metadata": {},
   "source": [
    "## **Numba CUDA Kernel (Advanced)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd230f-a6f7-409d-bef3-cbb0acb0d73f",
   "metadata": {},
   "source": [
    "[Numba CUDA](https://numba.pydata.org/numba-doc/latest/cuda/index.html) provides us with an extremely pythonic interface to developing CUDA kernels without ever writing a single line of C/C++. It's pythonic syntax makes writing CUDA approachable to your typical data scientist. Numba CUDA exposes lower control to the developer including the use of shared memory, constant memory, atomics, warp level optimizations, and many others. Although not every element of CUDA is supported, developers are able to prototype highly performant algorithms very quickly. In many cases, these can be production ready techniques.\n",
    "\n",
    "Numba CUDA implements the CUDA Array Interface, which means GPU data structures are interoperable between CuPy, cuDF, and Deep Learning Frameworks (Tensorflow, PyTorch). This is compelling from an end to end data processing perspecitve. Keeping the data on GPU for as long as possible let's developers avoid bottlenecks that creep in from unnecessary data copies across the PCIe bus.\n",
    "\n",
    "Below, we implement several kernels to perform the nearest neighbor calculations. To demonstrate lower level CUDA support, our code performs a [sequential addressing tree based warp reduction](https://developer.nvidia.com/blog/using-cuda-warp-level-primitives/), leveraging efficient communcation between threads within the same warp.\n",
    "\n",
    "Do not worry if we lost you here. Some of these are advanced concepts. The key takeaway is that more sophisticated CUDA programming is available to you without ever leaving the land of Python.\n",
    "\n",
    "Learn more about the CUDA Programming Model [here](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba8957-c7cc-4ea1-acb3-69dbbe0855b6",
   "metadata": {},
   "source": [
    "Here are our hand tuned Numba JIT CUDA kernels that deploy warp level optimization to solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeb29aa-1ac0-44aa-bbbc-8b7a5b496e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit(device=True, inline=True)\n",
    "def _warp_min_reduce_idx_unrolled(val, idx):\n",
    "    \n",
    "    mask  = 0xffffffff    \n",
    "        \n",
    "    shfl_val = cuda.shfl_down_sync(\n",
    "        mask, val, 16)\n",
    "    \n",
    "    shfl_idx = cuda.shfl_down_sync(\n",
    "        mask, idx, 16)\n",
    "\n",
    "    if val > shfl_val:\n",
    "        val = shfl_val\n",
    "        idx = shfl_idx\n",
    "        \n",
    "    shfl_val = cuda.shfl_down_sync(\n",
    "        mask, val, 8)\n",
    "    \n",
    "    shfl_idx = cuda.shfl_down_sync(\n",
    "        mask, idx, 8)\n",
    "\n",
    "    if val > shfl_val:\n",
    "        val = shfl_val\n",
    "        idx = shfl_idx        \n",
    "        \n",
    "    shfl_val = cuda.shfl_down_sync(\n",
    "        mask, val, 4)\n",
    "    \n",
    "    shfl_idx = cuda.shfl_down_sync(\n",
    "        mask, idx, 4)\n",
    "\n",
    "    if val > shfl_val:\n",
    "        val = shfl_val\n",
    "        idx = shfl_idx         \n",
    "        \n",
    "    shfl_val = cuda.shfl_down_sync(\n",
    "        mask, val, 2)\n",
    "    \n",
    "    shfl_idx = cuda.shfl_down_sync(\n",
    "        mask, idx, 2)\n",
    "\n",
    "    if val > shfl_val:\n",
    "        val = shfl_val\n",
    "        idx = shfl_idx         \n",
    "        \n",
    "    shfl_val = cuda.shfl_down_sync(\n",
    "        mask, val, 1)\n",
    "    \n",
    "    shfl_idx = cuda.shfl_down_sync(\n",
    "        mask, idx, 1)\n",
    "\n",
    "    if val > shfl_val:\n",
    "        val = shfl_val\n",
    "        idx = shfl_idx\n",
    "\n",
    "    return val, idx\n",
    "\n",
    "sig_block_get_nearest_brute = \"void(float32[:,:], float32[:,:], uint32[:,:], float32[:,:])\"\n",
    "def _block_get_nearest_brute(coord1, coord2, block_idx, block_dist):\n",
    "    \n",
    "    \"\"\"\n",
    "    GPU accelerated pairwise distance comparisons in single\n",
    "    precision.\n",
    "    \"\"\"    \n",
    "    \n",
    "    startx, starty = cuda.grid(2)\n",
    "    stridex, stridey = cuda.gridsize(2)\n",
    "    \n",
    "    seed = float32(1e11)\n",
    "        \n",
    "    for i in range(starty, coord2.shape[0], stridey):    \n",
    "        \n",
    "        b_min_val = seed\n",
    "        b_min_idx = uint32(0)\n",
    "        coord2_i_0 = coord2[i,0]\n",
    "        \n",
    "        for j in range(startx, coord1.shape[0], stridex):\n",
    "\n",
    "            coord1_j_0 = coord1[j,0]\n",
    "        \n",
    "            first_sin = sin(\n",
    "                (coord2_i_0 - coord1_j_0) * float32(0.5))\n",
    "            \n",
    "            second_sin = sin(\n",
    "                (coord2[i,1] - coord1[j, 1]) * float32(0.5))            \n",
    "\n",
    "            local_val = float32(2.0) * asin(\n",
    "                sqrt(\n",
    "                    first_sin * first_sin + \\\n",
    "                    cos(coord1_j_0) * \\\n",
    "                    cos(coord2_i_0) * \\\n",
    "                    second_sin * second_sin)\n",
    "            )            \n",
    "            \n",
    "            if local_val < b_min_val:\n",
    "                b_min_val = local_val\n",
    "                b_min_idx = j\n",
    "                \n",
    "                \n",
    "        b_min_val, b_min_idx = \\\n",
    "            _warp_min_reduce_idx_unrolled(\n",
    "            b_min_val, b_min_idx)\n",
    "\n",
    "        if cuda.laneid == 0:\n",
    "            block_dist[i, cuda.blockIdx.x] = b_min_val\n",
    "            block_idx[i, cuda.blockIdx.x] = b_min_idx\n",
    "            \n",
    "sig_global_get_nearest_brute = \"void(float32[:,:], uint32[:,:], float32[:], uint32[:])\"\n",
    "def _global_get_nearest_brute(block_dist, block_idx, out_dist, out_idx):        \n",
    "        \n",
    "    startx, starty = cuda.grid(2)\n",
    "    stridex, stridey = cuda.gridsize(2)\n",
    "    \n",
    "    seed = float32(1e30)\n",
    "    \n",
    "    for i in range(starty, out_dist.shape[0], stridey):\n",
    "        \n",
    "        g_min_dist = seed\n",
    "        g_min_idx = 0\n",
    "        \n",
    "        for j in range(startx, block_idx.shape[1], stridex):\n",
    "            \n",
    "            local_dist = block_dist[i, cuda.threadIdx.x]\n",
    "            \n",
    "            if local_dist < g_min_dist:\n",
    "                g_min_dist = local_dist\n",
    "                g_min_idx = block_idx[i, cuda.threadIdx.x]\n",
    "        \n",
    "        g_min_dist, g_min_idx = \\\n",
    "            _warp_min_reduce_idx_unrolled(\n",
    "            g_min_dist, g_min_idx)\n",
    "        \n",
    "        if cuda.laneid == 0:\n",
    "            out_dist[i] = g_min_dist\n",
    "            out_idx[i] = g_min_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9229dc17-e749-4d31-a23b-da465d3e99b1",
   "metadata": {},
   "source": [
    "Create our JIT kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e32c499-7362-4459-a0ff-c1eadb288501",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_min_reduce = cuda.jit(\n",
    "    sig_block_get_nearest_brute,        \n",
    "    fastmath=True)(_block_get_nearest_brute)\n",
    "\n",
    "global_min_reduce = cuda.jit(\n",
    "    sig_global_get_nearest_brute,        \n",
    "    fastmath=True)(_global_get_nearest_brute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d06a0c5-e682-49fb-8dd4-029c87839736",
   "metadata": {},
   "source": [
    "### **Call our CUDA Kernel**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13dd5b1-e893-4213-acc4-bcc27edec17d",
   "metadata": {},
   "source": [
    "The function below solves our nearest neighbor problem in two steps. \n",
    "\n",
    "First, generate an intermediate solution by performing block level warp reductions by finding the closest 32 points for each data observation. The number 32 was selected to be equal to the size of a warp.\n",
    "\n",
    "We demonstrate interoperability with CuPy by passing in CuPy device arrays to our kernel.\n",
    "\n",
    "```block_min_reduce[bpg, tpb](d_ref, d_obs, d_block_idx, d_block_dist)```\n",
    "\n",
    "Our first launch configuration:\n",
    "\n",
    "* 2D grid of 3456 (a multiple of the # of GPU SMs) blocks -- 32x108\n",
    "* Blocks contain 2D arrangement of 512 (a multiple of 32) threads -- 32x16\n",
    "* Total of 1,769,472 threads\n",
    "\n",
    "We make a second kernel call to find our global solution. Since our previous kernel implements block level parallelism, a second kernel call helps us with a global synchronization. In this phase, we compute a global solution to our nearest neighbor problem.\n",
    "\n",
    "```global_min_reduce[bpg, tpb](d_block_dist, d_block_idx, d_out_dist, d_out_idx)```\n",
    "\n",
    "Our second launch configuration:\n",
    "\n",
    "* 1D grid of 108*20 blocks (multiple of the # of SMs)\n",
    "* Blocks contain 2D arrangement of 512 (a multiple of 32) -- 32x16\n",
    "* Total of 1,105,920 threads\n",
    "\n",
    "We make sure the CPU waits for processing to complete before continuing by performing a global synchronization with ```cuda.synchronize()```\n",
    "\n",
    "We achieve our final solution!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4b2be4-9ea5-49ad-994d-8b218f877fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numba_cuda_solve(d_obs, d_ref):\n",
    "    \n",
    "    d_out_idx = cuda.device_array((d_obs.shape[0],), dtype=np.uint32)\n",
    "    d_out_dist = cuda.device_array((d_obs.shape[0],), dtype=np.float32)     \n",
    "    \n",
    "    d_block_idx = cuda.device_array(\n",
    "        (d_out_idx.shape[0], 32), \n",
    "        dtype=np.uint32)\n",
    "\n",
    "    d_block_dist = cuda.device_array(\n",
    "        (d_out_idx.shape[0], 32), \n",
    "        dtype=np.float32)           \n",
    "\n",
    "    bpg = 32, 128\n",
    "    tpb = 32, 16\n",
    "\n",
    "    block_min_reduce[bpg, tpb](\n",
    "        d_ref, \n",
    "        d_obs, \n",
    "        d_block_idx,\n",
    "        d_block_dist)   \n",
    "\n",
    "    bpg = (1, 128*20)\n",
    "    tpb = (32, 16)        \n",
    "\n",
    "    global_min_reduce[bpg, tpb](\n",
    "        d_block_dist, \n",
    "        d_block_idx, \n",
    "        d_out_dist, \n",
    "        d_out_idx)   \n",
    "        \n",
    "    cuda.synchronize()\n",
    "    \n",
    "    return d_out_idx, d_out_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb21e2f-dac4-4cba-a519-0192008ddd1f",
   "metadata": {},
   "source": [
    "Verify our Numba CUDA kernels are producing the correct results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c05b38-03f0-4e31-aea2-53f4197f9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_idx_nb_gpu_val, out_dist_nb_gpu_val = \\\n",
    "    numba_cuda_solve(d_obs_val, d_ref_val)\n",
    "\n",
    "print(\"Accuracy - Numba CUDA Single GPU:\", \n",
    "      check_accuracy(\n",
    "          d_obs_val, d_ref_val,\n",
    "          out_idx_nb_gpu_val, out_dist_nb_gpu_val)\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc0a175-4e1f-4b72-8c50-058c17bf5098",
   "metadata": {},
   "source": [
    "This Numba CUDA kernels complete on the demo system in ~10.8ms -- more than 200,000x faster than our baseline, and 1,129.6x faster than our most performant CPU option. In this scenario, Numba CUDA required more developer effort but provided us a framework to squeeze additional performance out of our system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08b2cd-e7f8-4a03-92f7-0615be4300f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "out_idx_nb_cuda, out_dist_nb_cuda = numba_cuda_solve(d_obs, d_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef552e46-3767-4874-816c-bad6eb66852c",
   "metadata": {},
   "source": [
    "## **Please restart the kernel**"
   ]
  },
  {
   "cell_type": "raw",
   "id": "92092932-203b-47c1-a676-86982274544d",
   "metadata": {},
   "source": [
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
